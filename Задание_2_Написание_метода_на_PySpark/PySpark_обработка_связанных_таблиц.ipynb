{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxc_3NWLfYiq",
        "outputId": "e295dfe0-1961-4fc4-de1d-eec5c1895b2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex_bxvbJos7j",
        "outputId": "b687f37a-0227-4c0c-d4ba-83a9d210c8a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "uJx2uf8FwrQX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"Test\").getOrCreate()"
      ],
      "metadata": {
        "id": "yg9pzsxpw5BH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "zEZtDihQxGmv",
        "outputId": "bc7dd59d-b321-4c1d-9cfd-8d571ec844af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.5.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Практическое задание 2: Работа с продуктами и категориями"
      ],
      "metadata": {
        "id": "k6gpxoL3zRHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Импорт библиотеки и создание SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = SparkSession.builder.appName('ProductsAndCategories').getOrCreate()"
      ],
      "metadata": {
        "id": "sOBxRVRAzq44"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Создание исходных датафреймов\n",
        "# Датафрейм с продуктами\n",
        "products_data = [\n",
        "    (1, 'Яблоко'),\n",
        "    (2, 'Молоко'),\n",
        "    (3, 'Хлеб'),\n",
        "    (4, 'Молярка'), # продукт без категории\n",
        "]\n",
        "products = spark.createDataFrame(products_data, ['product_id', 'product_name'])"
      ],
      "metadata": {
        "id": "luy-132Tz1M4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Датафрейм с категориями\n",
        "categories_data = [\n",
        "    (100, 'Фрукты'),\n",
        "    (101, 'Молочные'),\n",
        "    (102, 'Выпечка'),\n",
        "]\n",
        "categories = spark.createDataFrame(categories_data, ['category_id', 'category_name'])"
      ],
      "metadata": {
        "id": "qim5KnpSz-vh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Связь продукт—категория (многие-ко-многим)\n",
        "relations_data = [\n",
        "    (1, 100), # Яблоко — Фрукты\n",
        "    (2, 101), # Молоко — Молочные\n",
        "    (3, 102), # Хлеб — Выпечка\n",
        "    (2, 102), # Молоко — Выпечка (пример для многих категорий)\n",
        "    # Молярка без категории\n",
        "]\n",
        "relations = spark.createDataFrame(relations_data, ['product_id', 'category_id'])"
      ],
      "metadata": {
        "id": "2USLsTpj0NfT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 3. Метод: получение всех пар и продуктов без категории\n",
        "from pyspark.sql import DataFrame\n",
        "from typing import Tuple\n",
        "\n",
        "def get_product_category_pairs_and_orphans(products: DataFrame, categories: DataFrame, relations: DataFrame) -> Tuple[DataFrame, DataFrame]:\n",
        "    # Все пары продукт–категория (left join)\n",
        "    pairs = products.join(relations, on='product_id', how='left') \\\n",
        "                   .join(categories, on='category_id', how='left') \\\n",
        "                   .select('product_name', 'category_name')\n",
        "    # Все продукты без категории (где category_id == null после join)\n",
        "    orphans = pairs.filter(col('category_name').isNull()) \\\n",
        "                  .select('product_name')\n",
        "    return pairs, orphans"
      ],
      "metadata": {
        "id": "o37cbBJY0aY5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. Проверка работы метода (вывод результатов)\n",
        "pairs_df, orphans_df = get_product_category_pairs_and_orphans(products, categories, relations)\n",
        "print('Пары продукт–категория:')\n",
        "pairs_df.show()\n",
        "print('Продукты без категории:')\n",
        "orphans_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTNLDykQ0k1Z",
        "outputId": "d01576ac-2695-422e-f945-c512cbc20d06"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пары продукт–категория:\n",
            "+------------+-------------+\n",
            "|product_name|category_name|\n",
            "+------------+-------------+\n",
            "|      Яблоко|       Фрукты|\n",
            "|      Молоко|      Выпечка|\n",
            "|      Молоко|     Молочные|\n",
            "|        Хлеб|      Выпечка|\n",
            "|     Молярка|         NULL|\n",
            "+------------+-------------+\n",
            "\n",
            "Продукты без категории:\n",
            "+------------+\n",
            "|product_name|\n",
            "+------------+\n",
            "|     Молярка|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 5. Тесты (простые asserts)\n",
        "result_pairs = set([(r['product_name'], r['category_name']) for r in pairs_df.collect()])\n",
        "result_orphans = set([r['product_name'] for r in orphans_df.collect()])\n",
        "\n",
        "assert ('Яблоко', 'Фрукты') in result_pairs\n",
        "assert ('Молоко', 'Молочные') in result_pairs\n",
        "assert ('Молоко', 'Выпечка') in result_pairs\n",
        "assert ('Хлеб', 'Выпечка') in result_pairs\n",
        "assert ('Молярка', None) in result_pairs  # None тут — нет категории\n",
        "assert 'Молярка' in result_orphans        # Проверяем «сирот»"
      ],
      "metadata": {
        "id": "MCVRoiIP06ed"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "**Подсказка для закрепления:**\n",
        "- Почему используем 'left join'?\n",
        "- Почему ищем None (null) в категории?\n",
        "\n",
        "**Почему используем `left join`?**\n",
        "\n",
        "`left join` используется потому, что мы хотим получить все продукты, даже если у них нет связанных категорий.  \n",
        "Если бы использовали обычный (`inner join`), то продукты без категорий просто исчезли бы из результата.\n",
        "\n",
        "- **`left join`** — сохраняет все строки из левой таблицы (products), даже если для них нет совпадающей строки в правой таблице (relations или categories).\n",
        "- Именно благодаря этому мы можем увидеть продукты без категорий в итоговом датафрейме.\n",
        "\n",
        "**Почему ищем `None` (`null`) в категории?**\n",
        "\n",
        "Когда после объединения (join) для продукта не нашлась соответствующая категория, в поле категории появляется значение `null` (в Spark — `None`).  \n",
        "То есть, если у продукта нет ни одной связи с категорией, после join в поле `category_name` будет `null`.\n",
        "\n",
        "- Мы подсвечиваем именно такие случаи — это продукты, не относящиеся ни к одной категории.\n",
        "- Такой фильтр помогает “вытащить” все продукты-“сироты” для вашего второго условия задачи.\n",
        "\n",
        "**В итоге:**\n",
        "- `left join` → чтобы не потерять продукты, даже если нет категории.\n",
        "- Поиск `None` → чтобы найти “сирот” — продукты без категории."
      ],
      "metadata": {
        "id": "IL-Hipq81NME"
      }
    }
  ]
}